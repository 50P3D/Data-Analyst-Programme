{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950d7d13",
   "metadata": {},
   "source": [
    "Purpose: Download all F1 data (FP1, FP2, FP3, Q, Sprint, Race) from 2021-2025 in batches, respecting API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f57a83",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "F1 DATA DOWNLOADER - REVERSE CHRONOLOGICAL ORDER\n",
    "=================================================\n",
    "Downloads all F1 session data starting from the LATEST races (Dec 2025)\n",
    "working backwards to 2021. This ensures you get the most recent data first.\n",
    "\n",
    "API CAPACITY ESTIMATE:\n",
    "- Per session: ~11 API calls (3 for loading + 8 for data)\n",
    "- Per race weekend: ~55 calls (5 sessions: FP1, FP2, FP3, Q, R)\n",
    "- API Limit: 500 calls/hour\n",
    "- EXPECTED: ~8-9 race weekends per hour\n",
    "\n",
    "USAGE:\n",
    "1. Run this script: python 1_download_data.py\n",
    "2. Wait for API limit message\n",
    "3. Wait 1 hour, run again - it resumes automatically\n",
    "4. Repeat until all data is downloaded\n",
    "\n",
    "OUTPUT:\n",
    "- f1_data/2025_races.csv\n",
    "- f1_data/2025_qualifying.csv\n",
    "- f1_data/2025_practice.csv\n",
    "- ... (same for 2024-2021)\n",
    "\"\"\"\n",
    "\n",
    "import fastf1 as ff1\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "ff1.set_log_level('ERROR')\n",
    "ff1.Cache.enable_cache('fastf1_cache')\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "YEARS = [2025, 2024, 2023, 2022, 2021]  # â† REVERSED: Newest first!\n",
    "SESSION_TYPES = {\n",
    "    'FP1': 'practice',\n",
    "    'FP2': 'practice', \n",
    "    'FP3': 'practice',\n",
    "    'Q': 'qualifying',\n",
    "    'SQ': 'qualifying',  # Sprint Qualifying\n",
    "    'S': 'sprint',       # Sprint Race\n",
    "    'R': 'race'\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = 'f1_data'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MAX_API_CALLS = 400  # Conservative limit (actual is 500/hour)\n",
    "api_call_count = 0\n",
    "session_count = 0\n",
    "race_weekend_count = 0\n",
    "\n",
    "# ==============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_api_limit():\n",
    "    \"\"\"Check if we're approaching API limit\"\"\"\n",
    "    global api_call_count, race_weekend_count\n",
    "    if api_call_count >= MAX_API_CALLS:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"âš ï¸  API LIMIT REACHED: {api_call_count} calls\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"âœ… Downloaded {race_weekend_count} race weekends this session\")\n",
    "        print(f\"âœ… Progress saved to: {OUTPUT_DIR}/\")\n",
    "        print(f\"ðŸ’¤ Wait 1 hour, then run this script again to continue\")\n",
    "        print(f\"â„¹ï¸  Already downloaded sessions will be skipped automatically\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def session_already_downloaded(year, event_name, session_type):\n",
    "    \"\"\"Check if session data already exists\"\"\"\n",
    "    category = SESSION_TYPES.get(session_type, 'other')\n",
    "    \n",
    "    if category == 'practice':\n",
    "        file_path = os.path.join(OUTPUT_DIR, f'{year}_practice.csv')\n",
    "    elif category == 'qualifying':\n",
    "        file_path = os.path.join(OUTPUT_DIR, f'{year}_qualifying.csv')\n",
    "    elif category == 'sprint':\n",
    "        file_path = os.path.join(OUTPUT_DIR, f'{year}_sprint.csv')\n",
    "    elif category == 'race':\n",
    "        file_path = os.path.join(OUTPUT_DIR, f'{year}_races.csv')\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return False\n",
    "    \n",
    "    # Check if this specific event exists in the file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        exists = ((df['Year'] == year) & \n",
    "                  (df['Event'] == event_name) & \n",
    "                  (df['SessionType'] == session_type)).any()\n",
    "        return exists\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def append_to_csv(data, year, category):\n",
    "    \"\"\"Append data to year-category CSV file\"\"\"\n",
    "    file_path = os.path.join(OUTPUT_DIR, f'{year}_{category}.csv')\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        data.to_csv(file_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "def event_fully_downloaded(year, event_name):\n",
    "    \"\"\"Check if all sessions for this event are already downloaded\"\"\"\n",
    "    required_sessions = ['FP1', 'FP2', 'FP3', 'Q', 'R']\n",
    "    for session_type in required_sessions:\n",
    "        if not session_already_downloaded(year, event_name, session_type):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ==============================================================================\n",
    "# DOWNLOAD FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def download_session(year, event_name, session_type):\n",
    "    \"\"\"\n",
    "    Download a single session's data\n",
    "    Returns: (success, lap_count, api_calls_used)\n",
    "    \"\"\"\n",
    "    global api_call_count, session_count\n",
    "    \n",
    "    calls_before = api_call_count\n",
    "    \n",
    "    try:\n",
    "        # Load session\n",
    "        session = ff1.get_session(year, event_name, session_type)\n",
    "        api_call_count += 3  # Estimate\n",
    "        \n",
    "        # Load data\n",
    "        session.load(laps=True, telemetry=False, weather=True, messages=False)\n",
    "        api_call_count += 8  # Estimate\n",
    "        \n",
    "        if session.laps.empty:\n",
    "            return False, 0, api_call_count - calls_before\n",
    "        \n",
    "        # Extract lap data\n",
    "        laps = session.laps.copy()\n",
    "        \n",
    "        # Filter out invalid laps\n",
    "        if 'Deleted' in laps.columns:\n",
    "            laps = laps[laps['Deleted'] == False]\n",
    "        if 'IsAccurate' in laps.columns:\n",
    "            laps = laps[laps['IsAccurate'] == True]\n",
    "        \n",
    "        # Add metadata\n",
    "        laps['Year'] = year\n",
    "        laps['Event'] = event_name\n",
    "        laps['SessionType'] = session_type\n",
    "        \n",
    "        # Add weather data\n",
    "        try:\n",
    "            if session.weather_data is not None and not session.weather_data.empty:\n",
    "                weather = session.weather_data\n",
    "                laps['AirTemp'] = weather['AirTemp'].mean()\n",
    "                laps['TrackTemp'] = weather['TrackTemp'].mean()\n",
    "                laps['Humidity'] = weather['Humidity'].mean()\n",
    "                laps['Pressure'] = weather['Pressure'].mean()\n",
    "                laps['Rainfall'] = weather['Rainfall'].max()\n",
    "                laps['WindSpeed'] = weather['WindSpeed'].mean()\n",
    "                laps['WindDirection'] = weather['WindDirection'].mean()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Add session results (final positions)\n",
    "        try:\n",
    "            if session.results is not None and not session.results.empty:\n",
    "                results = session.results[['Abbreviation', 'Position', 'GridPosition', 'Status']].copy()\n",
    "                results.rename(columns={\n",
    "                    'Abbreviation': 'Driver',\n",
    "                    'Position': 'FinalPosition',\n",
    "                    'GridPosition': 'StartPosition'\n",
    "                }, inplace=True)\n",
    "                \n",
    "                laps = laps.merge(results, on='Driver', how='left', suffixes=('', '_result'))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Save to appropriate CSV\n",
    "        category = SESSION_TYPES.get(session_type, 'other')\n",
    "        if category != 'other':\n",
    "            append_to_csv(laps, year, category)\n",
    "        \n",
    "        session_count += 1\n",
    "        return True, len(laps), api_call_count - calls_before\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, 0, api_call_count - calls_before\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN DOWNLOAD LOOP\n",
    "# ==============================================================================\n",
    "\n",
    "def download_all_data():\n",
    "    \"\"\"Main function to download all data\"\"\"\n",
    "    global api_call_count, race_weekend_count\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"F1 DATA DOWNLOADER - REVERSE CHRONOLOGICAL ORDER\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ðŸ“… Years: {YEARS[0]} â†’ {YEARS[-1]} (newest first)\")\n",
    "    print(f\"ðŸ Sessions per race: FP1, FP2, FP3, Q, Sprint (if any), R\")\n",
    "    print(f\"ðŸ“Š API Limit: {MAX_API_CALLS} calls/hour\")\n",
    "    print(f\"\")\n",
    "    print(f\"ðŸ’¡ CAPACITY ESTIMATE:\")\n",
    "    print(f\"   - Per session: ~11 API calls\")\n",
    "    print(f\"   - Per race weekend: ~55 calls (5 sessions)\")\n",
    "    print(f\"   - Expected download: ~7-8 race weekends per hour\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    total_sessions = 0\n",
    "    skipped_sessions = 0\n",
    "    failed_sessions = 0\n",
    "    \n",
    "    for year in YEARS:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ðŸ“… YEAR {year}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            # Get event schedule\n",
    "            schedule = ff1.get_event_schedule(year)\n",
    "            api_call_count += 1\n",
    "            \n",
    "            # REVERSE THE SCHEDULE: Latest races first\n",
    "            schedule = schedule.iloc[::-1].reset_index(drop=True)\n",
    "            \n",
    "            print(f\"Found {len(schedule)} events (downloading newest first)\")\n",
    "            \n",
    "            for idx, event in schedule.iterrows():\n",
    "                event_name = event['EventName']\n",
    "                \n",
    "                # Check if event is fully downloaded\n",
    "                if event_fully_downloaded(year, event_name):\n",
    "                    print(f\"\\nðŸ {event_name}\")\n",
    "                    print(f\"   â­ï¸  Complete: All sessions already downloaded\")\n",
    "                    continue\n",
    "                \n",
    "                # Check API limit before starting new race weekend\n",
    "                if check_api_limit():\n",
    "                    return\n",
    "                \n",
    "                print(f\"\\nðŸ {event_name}\")\n",
    "                \n",
    "                event_sessions_downloaded = 0\n",
    "                event_sessions_total = 0\n",
    "                \n",
    "                # Try each session type\n",
    "                for session_type in ['FP1', 'FP2', 'FP3', 'Q', 'SQ', 'S', 'R']:\n",
    "                    \n",
    "                    # Check if already downloaded\n",
    "                    if session_already_downloaded(year, event_name, session_type):\n",
    "                        skipped_sessions += 1\n",
    "                        print(f\"   â­ï¸  {session_type:3s}: Already downloaded\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Check API limit again\n",
    "                    if check_api_limit():\n",
    "                        return\n",
    "                    \n",
    "                    # Download session\n",
    "                    success, lap_count, calls_used = download_session(year, event_name, session_type)\n",
    "                    \n",
    "                    if success:\n",
    "                        total_sessions += 1\n",
    "                        event_sessions_downloaded += 1\n",
    "                        event_sessions_total += 1\n",
    "                        print(f\"   âœ… {session_type:3s}: {lap_count:4d} laps ({calls_used} calls) | Total: {api_call_count}/{MAX_API_CALLS}\")\n",
    "                    else:\n",
    "                        failed_sessions += 1\n",
    "                        if session_type in ['FP1', 'FP2', 'FP3', 'Q', 'R']:  # Only show important sessions\n",
    "                            print(f\"   âš ï¸  {session_type:3s}: Not available\")\n",
    "                    \n",
    "                    # Small delay to be nice to API\n",
    "                    time.sleep(0.5)\n",
    "                \n",
    "                # Increment race weekend count if we downloaded at least one session\n",
    "                if event_sessions_downloaded > 0:\n",
    "                    race_weekend_count += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Year {year} error: {str(e)[:80]}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ… DOWNLOAD COMPLETE!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"âœ… Downloaded: {total_sessions} sessions ({race_weekend_count} race weekends)\")\n",
    "    print(f\"â­ï¸  Skipped: {skipped_sessions} sessions (already had)\")\n",
    "    print(f\"âš ï¸  Failed: {failed_sessions} sessions (not available)\")\n",
    "    print(f\"ðŸ“Š API Calls Used: {api_call_count}/{MAX_API_CALLS}\")\n",
    "    print(f\"ðŸ’¾ Data saved to: {OUTPUT_DIR}/\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SHOW CURRENT PROGRESS\n",
    "# ==============================================================================\n",
    "\n",
    "def show_current_progress():\n",
    "    \"\"\"Show what data has been downloaded so far\"\"\"\n",
    "    print(\"\\nðŸ“Š Current Download Status:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_laps = 0\n",
    "    total_events = 0\n",
    "    \n",
    "    for year in [2025, 2024, 2023, 2022, 2021]:\n",
    "        year_events = set()\n",
    "        \n",
    "        for category in ['practice', 'qualifying', 'sprint', 'races']:\n",
    "            file_path = os.path.join(OUTPUT_DIR, f'{year}_{category}.csv')\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "                laps = len(df)\n",
    "                events = df['Event'].nunique() if 'Event' in df.columns else 0\n",
    "                total_laps += laps\n",
    "                year_events.update(df['Event'].unique() if 'Event' in df.columns else [])\n",
    "                print(f\"   âœ… {year}_{category:12s}.csv: {laps:6d} laps, {events:2d} events\")\n",
    "        \n",
    "        if year_events:\n",
    "            total_events += len(year_events)\n",
    "            print(f\"      â†’ {year} total: {len(year_events)} unique events\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Overall Progress:\")\n",
    "    print(f\"   Total laps: {total_laps:,}\")\n",
    "    print(f\"   Total race weekends: {total_events}\")\n",
    "    \n",
    "    # Estimate remaining\n",
    "    # F1 season typically has ~23 races per year Ã— 5 years = ~115 total\n",
    "    estimated_total = 115\n",
    "    remaining = estimated_total - total_events\n",
    "    \n",
    "    if remaining > 0:\n",
    "        hours_needed = (remaining / 8)  # ~8 races per hour\n",
    "        print(f\"\\nâ±ï¸  Estimated remaining:\")\n",
    "        print(f\"   Race weekends: ~{remaining}\")\n",
    "        print(f\"   Time needed: ~{hours_needed:.1f} more hours of downloading\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# RUN\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nðŸš€ Starting F1 data download (newest races first)...\")\n",
    "    print(\"â„¹ï¸  This respects API rate limits - may need multiple runs\\n\")\n",
    "    \n",
    "    # Show what we already have\n",
    "    show_current_progress()\n",
    "    \n",
    "    print(\"\\nâ³ Starting download...\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    download_all_data()\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Show final status\n",
    "    show_current_progress()\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Session duration: {elapsed/60:.1f} minutes\")\n",
    "    print(f\"ðŸ“Š API calls used: {api_call_count}\")\n",
    "    print(f\"ðŸ Race weekends downloaded: {race_weekend_count}\")\n",
    "    \n",
    "    if api_call_count > 0:\n",
    "        print(f\"ðŸ“ˆ Average: {api_call_count/max(1, race_weekend_count):.1f} API calls per race weekend\")\n",
    "    \n",
    "    print(\"\\nâœ… Ready for next step: python 2_train_model.py\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bf4f5",
   "metadata": {},
   "source": [
    "Purpose: Load downloaded data, aggregate features, train model on 2021-2024, save model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf4cc2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "F1 RACE POSITION PREDICTOR - TRAINING\n",
    "======================================\n",
    "Trains a machine learning model to predict race finishing positions\n",
    "using 2021-2024 data.\n",
    "\n",
    "FEATURES:\n",
    "- Qualifying position\n",
    "- Practice pace (FP1, FP2, FP3 average lap times)\n",
    "- Weather conditions\n",
    "- Driver/Team historical performance\n",
    "- Track characteristics\n",
    "\n",
    "USAGE:\n",
    "python 2_train_model.py\n",
    "\n",
    "OUTPUT:\n",
    "- f1_trained_model.pkl (saved model)\n",
    "- training_report.txt (performance metrics)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "DATA_DIR = 'f1_data'\n",
    "TRAINING_YEARS = [2021, 2022, 2023, 2024]\n",
    "OUTPUT_MODEL = 'f1_trained_model.pkl'\n",
    "OUTPUT_REPORT = 'training_report.txt'\n",
    "\n",
    "# ==============================================================================\n",
    "# LOAD DATA\n",
    "# ==============================================================================\n",
    "\n",
    "def load_all_data(years):\n",
    "    \"\"\"Load race and qualifying data for specified years\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    all_races = []\n",
    "    all_quali = []\n",
    "    all_practice = []\n",
    "    all_sprint = []\n",
    "    \n",
    "    for year in years:\n",
    "        # Load races\n",
    "        race_file = os.path.join(DATA_DIR, f'{year}_races.csv')\n",
    "        if os.path.exists(race_file):\n",
    "            races = pd.read_csv(race_file)\n",
    "            all_races.append(races)\n",
    "            print(f\"âœ… {year} Races: {len(races):,} laps\")\n",
    "        \n",
    "        # Load qualifying\n",
    "        quali_file = os.path.join(DATA_DIR, f'{year}_qualifying.csv')\n",
    "        if os.path.exists(quali_file):\n",
    "            quali = pd.read_csv(quali_file)\n",
    "            all_quali.append(quali)\n",
    "            print(f\"âœ… {year} Qualifying: {len(quali):,} laps\")\n",
    "        \n",
    "        # Load practice\n",
    "        practice_file = os.path.join(DATA_DIR, f'{year}_practice.csv')\n",
    "        if os.path.exists(practice_file):\n",
    "            practice = pd.read_csv(practice_file)\n",
    "            all_practice.append(practice)\n",
    "            print(f\"âœ… {year} Practice: {len(practice):,} laps\")\n",
    "        \n",
    "        # Load sprint\n",
    "        sprint_file = os.path.join(DATA_DIR, f'{year}_sprint.csv')\n",
    "        if os.path.exists(sprint_file):\n",
    "            sprint = pd.read_csv(sprint_file)\n",
    "            all_sprint.append(sprint)\n",
    "            print(f\"âœ… {year} Sprint: {len(sprint):,} laps\")\n",
    "    \n",
    "    races_df = pd.concat(all_races, ignore_index=True) if all_races else pd.DataFrame()\n",
    "    quali_df = pd.concat(all_quali, ignore_index=True) if all_quali else pd.DataFrame()\n",
    "    practice_df = pd.concat(all_practice, ignore_index=True) if all_practice else pd.DataFrame()\n",
    "    sprint_df = pd.concat(all_sprint, ignore_index=True) if all_sprint else pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\nâœ… Total loaded:\")\n",
    "    print(f\"   Races: {len(races_df):,} laps\")\n",
    "    print(f\"   Qualifying: {len(quali_df):,} laps\")\n",
    "    print(f\"   Practice: {len(practice_df):,} laps\")\n",
    "    print(f\"   Sprint: {len(sprint_df):,} laps\")\n",
    "    \n",
    "    return races_df, quali_df, practice_df, sprint_df\n",
    "\n",
    "# ==============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ==============================================================================\n",
    "\n",
    "def aggregate_race_data(races_df):\n",
    "    \"\"\"Aggregate lap-level race data to driver-race level\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"AGGREGATING RACE DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Convert lap times\n",
    "    races_df['LapTime_sec'] = pd.to_timedelta(races_df['LapTime'], errors='coerce').dt.total_seconds()\n",
    "    \n",
    "    # Filter valid laps (no pit in/out)\n",
    "    races_clean = races_df.copy()\n",
    "    if 'PitOutTime' in races_clean.columns:\n",
    "        races_clean = races_clean[races_clean['PitOutTime'].isna()]\n",
    "    if 'PitInTime' in races_clean.columns:\n",
    "        races_clean = races_clean[races_clean['PitInTime'].isna()]\n",
    "    \n",
    "    # Remove extreme outliers\n",
    "    races_clean = races_clean[races_clean['LapTime_sec'].notna()]\n",
    "    races_clean = races_clean[races_clean['LapTime_sec'] > 0]\n",
    "    races_clean = races_clean[races_clean['LapTime_sec'] < 200]\n",
    "    \n",
    "    print(f\"Valid racing laps: {len(races_clean):,}\")\n",
    "    \n",
    "    # Aggregate\n",
    "    agg_dict = {\n",
    "        'LapTime_sec': 'median',\n",
    "        'SpeedI1': 'mean',\n",
    "        'SpeedI2': 'mean',\n",
    "        'SpeedFL': 'mean',\n",
    "        'SpeedST': 'mean',\n",
    "        'AirTemp': 'first',\n",
    "        'TrackTemp': 'first',\n",
    "        'Humidity': 'first',\n",
    "        'Pressure': 'first',\n",
    "        'Rainfall': 'max',\n",
    "        'WindSpeed': 'mean',\n",
    "        'FinalPosition': 'first',\n",
    "        'StartPosition': 'first',\n",
    "        'Team': 'first'\n",
    "    }\n",
    "    \n",
    "    agg_dict = {k: v for k, v in agg_dict.items() if k in races_clean.columns}\n",
    "    \n",
    "    race_aggregated = races_clean.groupby(['Year', 'Event', 'Driver']).agg(agg_dict).reset_index()\n",
    "    \n",
    "    print(f\"Aggregated: {len(race_aggregated):,} driver-race records\")\n",
    "    \n",
    "    return race_aggregated\n",
    "\n",
    "def aggregate_qualifying(quali_df):\n",
    "    \"\"\"Get best qualifying lap per driver per event\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PROCESSING QUALIFYING DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    quali_df['LapTime_sec'] = pd.to_timedelta(quali_df['LapTime'], errors='coerce').dt.total_seconds()\n",
    "    \n",
    "    # Remove deleted laps\n",
    "    if 'Deleted' in quali_df.columns:\n",
    "        quali_df = quali_df[quali_df['Deleted'] == False]\n",
    "    \n",
    "    quali_df = quali_df[quali_df['LapTime_sec'].notna()]\n",
    "    quali_df = quali_df[quali_df['LapTime_sec'] > 0]\n",
    "    \n",
    "    # Get best lap and average speed per driver per event\n",
    "    quali_agg = quali_df.groupby(['Year', 'Event', 'Driver']).agg({\n",
    "        'LapTime_sec': 'min',\n",
    "        'SpeedI1': 'mean',\n",
    "        'SpeedFL': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate qualifying position from lap times\n",
    "    quali_agg['QualiPosition'] = quali_agg.groupby(['Year', 'Event'])['LapTime_sec'].rank(method='min')\n",
    "    \n",
    "    quali_agg.rename(columns={\n",
    "        'LapTime_sec': 'Quali_BestLapTime',\n",
    "        'SpeedI1': 'Quali_AvgSpeed',\n",
    "        'SpeedFL': 'Quali_MaxSpeed'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    print(f\"Qualifying records: {len(quali_agg):,}\")\n",
    "    \n",
    "    return quali_agg\n",
    "\n",
    "def aggregate_practice(practice_df):\n",
    "    \"\"\"Get average practice pace per driver per event\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PROCESSING PRACTICE DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if practice_df.empty:\n",
    "        print(\"No practice data available\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    practice_df['LapTime_sec'] = pd.to_timedelta(practice_df['LapTime'], errors='coerce').dt.total_seconds()\n",
    "    \n",
    "    # Filter valid laps\n",
    "    if 'Deleted' in practice_df.columns:\n",
    "        practice_df = practice_df[practice_df['Deleted'] == False]\n",
    "    \n",
    "    practice_df = practice_df[practice_df['LapTime_sec'].notna()]\n",
    "    practice_df = practice_df[practice_df['LapTime_sec'] > 0]\n",
    "    practice_df = practice_df[practice_df['LapTime_sec'] < 200]\n",
    "    \n",
    "    # Aggregate per driver per event\n",
    "    practice_agg = practice_df.groupby(['Year', 'Event', 'Driver']).agg({\n",
    "        'LapTime_sec': 'median',\n",
    "        'SpeedI1': 'mean',\n",
    "        'SpeedST': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    practice_agg.rename(columns={\n",
    "        'LapTime_sec': 'Practice_MedianLapTime',\n",
    "        'SpeedI1': 'Practice_AvgSpeed',\n",
    "        'SpeedST': 'Practice_MaxSpeed'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    print(f\"Practice records: {len(practice_agg):,}\")\n",
    "    \n",
    "    return practice_agg\n",
    "\n",
    "def process_sprint(sprint_df):\n",
    "    \"\"\"Process sprint race data - sprint results become grid positions\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PROCESSING SPRINT DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if sprint_df.empty:\n",
    "        print(\"No sprint data available\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get sprint results (final positions)\n",
    "    sprint_results = sprint_df.groupby(['Year', 'Event', 'Driver']).agg({\n",
    "        'FinalPosition': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    sprint_results.rename(columns={'FinalPosition': 'SprintPosition'}, inplace=True)\n",
    "    \n",
    "    print(f\"Sprint records: {len(sprint_results):,}\")\n",
    "    \n",
    "    return sprint_results\n",
    "\n",
    "def merge_all_features(race_agg, quali_agg, practice_agg, sprint_agg):\n",
    "    \"\"\"Merge all features together\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MERGING FEATURES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Start with race data\n",
    "    data = race_agg.copy()\n",
    "    \n",
    "    # Merge qualifying\n",
    "    if not quali_agg.empty:\n",
    "        data = data.merge(quali_agg, on=['Year', 'Event', 'Driver'], how='left')\n",
    "        print(f\"âœ… Merged qualifying data\")\n",
    "    \n",
    "    # Merge practice\n",
    "    if not practice_agg.empty:\n",
    "        data = data.merge(practice_agg, on=['Year', 'Event', 'Driver'], how='left')\n",
    "        print(f\"âœ… Merged practice data\")\n",
    "    \n",
    "    # Merge sprint\n",
    "    if not sprint_agg.empty:\n",
    "        data = data.merge(sprint_agg, on=['Year', 'Event', 'Driver'], how='left')\n",
    "        print(f\"âœ… Merged sprint data\")\n",
    "        \n",
    "        # Use sprint position as starting position if available\n",
    "        data['StartPosition'] = data['SprintPosition'].fillna(data['StartPosition'])\n",
    "    \n",
    "    # Use qualifying position as starting position if StartPosition is missing\n",
    "    data['StartPosition'] = data['StartPosition'].fillna(data['QualiPosition'])\n",
    "    \n",
    "    print(f\"\\nFinal dataset: {len(data):,} records\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def engineer_features(data):\n",
    "    \"\"\"Create additional features\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"FEATURE ENGINEERING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Speed features\n",
    "    speed_cols = [c for c in ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST'] if c in data.columns]\n",
    "    if speed_cols:\n",
    "        data['Race_AvgSpeed'] = data[speed_cols].mean(axis=1)\n",
    "    \n",
    "    # Weather features\n",
    "    if 'TrackTemp' in data.columns and 'AirTemp' in data.columns:\n",
    "        data['TempDiff'] = data['TrackTemp'] - data['AirTemp']\n",
    "    \n",
    "    if 'Rainfall' in data.columns:\n",
    "        data['IsWet'] = (data['Rainfall'] > 0).astype(int)\n",
    "    \n",
    "    # Pace delta (practice vs qualifying)\n",
    "    if 'Practice_MedianLapTime' in data.columns and 'Quali_BestLapTime' in data.columns:\n",
    "        data['PaceDelta'] = data['Practice_MedianLapTime'] - data['Quali_BestLapTime']\n",
    "    \n",
    "    # Historical driver performance (rolling average of past positions)\n",
    "    data = data.sort_values(['Driver', 'Year', 'Event'])\n",
    "    data['Driver_AvgPosition'] = data.groupby('Driver')['FinalPosition'].transform(\n",
    "        lambda x: x.shift(1).rolling(window=5, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Historical team performance\n",
    "    data['Team_AvgPosition'] = data.groupby('Team')['FinalPosition'].transform(\n",
    "        lambda x: x.shift(1).rolling(window=5, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Encode categoricals\n",
    "    encoders = {}\n",
    "    for col in ['Driver', 'Team', 'Event']:\n",
    "        if col in data.columns:\n",
    "            le = LabelEncoder()\n",
    "            data[f'{col}_encoded'] = le.fit_transform(data[col].astype(str))\n",
    "            encoders[col] = le\n",
    "    \n",
    "    print(f\"âœ… Created engineered features\")\n",
    "    print(f\"âœ… Encoded categorical variables\")\n",
    "    \n",
    "    return data, encoders\n",
    "\n",
    "# ==============================================================================\n",
    "# TRAINING\n",
    "# ==============================================================================\n",
    "\n",
    "def train_model(data):\n",
    "    \"\"\"Train model and evaluate\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Remove records without final position\n",
    "    data = data.dropna(subset=['FinalPosition'])\n",
    "    \n",
    "    # Feature candidates\n",
    "    feature_candidates = [\n",
    "        # Starting position (most important!)\n",
    "        'StartPosition',\n",
    "        'QualiPosition',\n",
    "        \n",
    "        # Qualifying performance\n",
    "        'Quali_BestLapTime',\n",
    "        'Quali_AvgSpeed',\n",
    "        'Quali_MaxSpeed',\n",
    "        \n",
    "        # Practice performance\n",
    "        'Practice_MedianLapTime',\n",
    "        'Practice_AvgSpeed',\n",
    "        'Practice_MaxSpeed',\n",
    "        \n",
    "        # Race pace\n",
    "        'LapTime_sec',\n",
    "        'Race_AvgSpeed',\n",
    "        \n",
    "        # Weather\n",
    "        'AirTemp',\n",
    "        'TrackTemp',\n",
    "        'TempDiff',\n",
    "        'Humidity',\n",
    "        'Pressure',\n",
    "        'WindSpeed',\n",
    "        'IsWet',\n",
    "        \n",
    "        # Engineered\n",
    "        'PaceDelta',\n",
    "        'Driver_AvgPosition',\n",
    "        'Team_AvgPosition',\n",
    "        \n",
    "        # Encodings\n",
    "        'Driver_encoded',\n",
    "        'Team_encoded',\n",
    "        'Event_encoded'\n",
    "    ]\n",
    "    \n",
    "    # Only use features that exist\n",
    "    available_features = [f for f in feature_candidates if f in data.columns]\n",
    "    \n",
    "    print(f\"Available features: {len(available_features)}\")\n",
    "    \n",
    "    # Fill missing values\n",
    "    X = data[available_features].copy()\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    # Remove highly correlated features\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > 0.95)]\n",
    "    \n",
    "    if to_drop:\n",
    "        print(f\"Dropping {len(to_drop)} highly correlated features: {to_drop}\")\n",
    "        X = X.drop(columns=to_drop)\n",
    "        available_features = [f for f in available_features if f not in to_drop]\n",
    "    \n",
    "    print(f\"Final features: {len(available_features)}\")\n",
    "    \n",
    "    y = data['FinalPosition']\n",
    "    \n",
    "    print(f\"\\nTraining samples: {len(X):,}\")\n",
    "    print(f\"Features: {available_features[:10]}...\")\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nðŸ¤– Training Random Forest...\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    print(f\"\\nâœ… Training complete!\")\n",
    "    print(f\"   RMSE: {rmse:.2f} positions\")\n",
    "    print(f\"   MAE:  {mae:.2f} positions\")\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Top 10 Most Important Features:\")\n",
    "    for idx, row in importance.head(10).iterrows():\n",
    "        print(f\"   {row['Feature']:30s} {row['Importance']:.4f}\")\n",
    "    \n",
    "    return model, available_features, importance, rmse, mae\n",
    "\n",
    "# ==============================================================================\n",
    "# SAVE MODEL\n",
    "# ==============================================================================\n",
    "\n",
    "def save_model(model, features, encoders, importance, rmse, mae):\n",
    "    \"\"\"Save trained model and metadata\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SAVING MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'features': features,\n",
    "        'encoders': encoders,\n",
    "        'importance': importance,\n",
    "        'training_rmse': rmse,\n",
    "        'training_mae': mae\n",
    "    }\n",
    "    \n",
    "    with open(OUTPUT_MODEL, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    \n",
    "    print(f\"âœ… Model saved: {OUTPUT_MODEL}\")\n",
    "    \n",
    "    # Save report\n",
    "    with open(OUTPUT_REPORT, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"F1 RACE PREDICTION MODEL - TRAINING REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(f\"Training Years: 2021-2024\\n\")\n",
    "        f.write(f\"Model Type: Random Forest Regressor\\n\")\n",
    "        f.write(f\"Features Used: {len(features)}\\n\")\n",
    "        f.write(f\"Training RMSE: {rmse:.2f} positions\\n\")\n",
    "        f.write(f\"Training MAE: {mae:.2f} positions\\n\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"FEATURE IMPORTANCE (Top 20)\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(importance.head(20).to_string(index=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"âœ… Report saved: {OUTPUT_REPORT}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"F1 RACE PREDICTION - MODEL TRAINING\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Load data\n",
    "    races_df, quali_df, practice_df, sprint_df = load_all_data(TRAINING_YEARS)\n",
    "    \n",
    "    if races_df.empty:\n",
    "        print(\"\\nâŒ No race data found! Run 1_download_data.py first\")\n",
    "        return\n",
    "    \n",
    "    # Aggregate\n",
    "    race_agg = aggregate_race_data(races_df)\n",
    "    quali_agg = aggregate_qualifying(quali_df)\n",
    "    practice_agg = aggregate_practice(practice_df)\n",
    "    sprint_agg = process_sprint(sprint_df)\n",
    "    \n",
    "    # Merge\n",
    "    data = merge_all_features(race_agg, quali_agg, practice_agg, sprint_agg)\n",
    "    \n",
    "    # Engineer features\n",
    "    data, encoders = engineer_features(data)\n",
    "    \n",
    "    # Train\n",
    "    model, features, importance, rmse, mae = train_model(data)\n",
    "    \n",
    "    # Save\n",
    "    save_model(model, features, encoders, importance, rmse, mae)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ… TRAINING COMPLETE!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Next step: python 3_predict_2025.py\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfe95f",
   "metadata": {},
   "source": [
    "Purpose: Load trained model, predict 2025 race results, compare against actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f53570",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "F1 RACE PREDICTION - 2025 PREDICTIONS & EVALUATION\n",
    "==================================================\n",
    "Uses trained model to predict 2025 race results and compares against\n",
    "actual results.\n",
    "\n",
    "USAGE:\n",
    "python 3_predict_2025.py\n",
    "\n",
    "OUTPUT:\n",
    "- 2025_predictions.csv (predicted vs actual for all races)\n",
    "- evaluation_report.txt (detailed performance metrics)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "DATA_DIR = 'f1_data'\n",
    "MODEL_FILE = 'f1_trained_model.pkl'\n",
    "OUTPUT_PREDICTIONS = '2025_predictions.csv'\n",
    "OUTPUT_EVALUATION = 'evaluation_report.txt'\n",
    "\n",
    "# ==============================================================================\n",
    "# LOAD MODEL\n",
    "# ==============================================================================\n",
    "\n",
    "def load_trained_model():\n",
    "    \"\"\"Load the trained model\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING TRAINED MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(f\"âŒ Model file not found: {MODEL_FILE}\")\n",
    "        print(\"Run 2_train_model.py first!\")\n",
    "        return None\n",
    "    \n",
    "    with open(MODEL_FILE, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    print(f\"âœ… Model loaded: {MODEL_FILE}\")\n",
    "    print(f\"   Features: {len(model_data['features'])}\")\n",
    "    print(f\"   Training RMSE: {model_data['training_rmse']:.2f}\")\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "# ==============================================================================\n",
    "# LOAD 2025 DATA\n",
    "# ==============================================================================\n",
    "\n",
    "def load_2025_data():\n",
    "    \"\"\"Load all 2025 session data\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"LOADING 2025 DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    year = 2025\n",
    "    \n",
    "    # Load races\n",
    "    races_2025 = pd.DataFrame()\n",
    "    race_file = os.path.join(DATA_DIR, f'{year}_races.csv')\n",
    "    if os.path.exists(race_file):\n",
    "        races_2025 = pd.read_csv(race_file)\n",
    "        print(f\"âœ… Races: {len(races_2025):,} laps from {races_2025['Event'].nunique()} events\")\n",
    "    \n",
    "    # Load qualifying\n",
    "    quali_2025 = pd.DataFrame()\n",
    "    quali_file = os.path.join(DATA_DIR, f'{year}_qualifying.csv')\n",
    "    if os.path.exists(quali_file):\n",
    "        quali_2025 = pd.read_csv(quali_file)\n",
    "        print(f\"âœ… Qualifying: {len(quali_2025):,} laps\")\n",
    "    \n",
    "    # Load practice\n",
    "    practice_2025 = pd.DataFrame()\n",
    "    practice_file = os.path.join(DATA_DIR, f'{year}_practice.csv')\n",
    "    if os.path.exists(practice_file):\n",
    "        practice_2025 = pd.read_csv(practice_file)\n",
    "        print(f\"âœ… Practice: {len(practice_2025):,} laps\")\n",
    "    \n",
    "    # Load sprint\n",
    "    sprint_2025 = pd.DataFrame()\n",
    "    sprint_file = os.path.join(DATA_DIR, f'{year}_sprint.csv')\n",
    "    if os.path.exists(sprint_file):\n",
    "        sprint_2025 = pd.read_csv(sprint_file)\n",
    "        print(f\"âœ… Sprint: {len(sprint_2025):,} laps\")\n",
    "    \n",
    "    return races_2025, quali_2025, practice_2025, sprint_2025\n",
    "\n",
    "# ==============================================================================\n",
    "# PROCESS 2025 DATA (same as training)\n",
    "# ==============================================================================\n",
    "\n",
    "def process_2025_data(races_df, quali_df, practice_df, sprint_df, model_data):\n",
    "    \"\"\"Process 2025 data same way as training data\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PROCESSING 2025 DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Import processing functions from training\n",
    "    # (In practice, these would be in a shared module)\n",
    "    \n",
    "    # Aggregate races\n",
    "    races_df['LapTime_sec'] = pd.to_timedelta(races_df['LapTime'], errors='coerce').dt.total_seconds()\n",
    "    \n",
    "    races_clean = races_df.copy()\n",
    "    if 'PitOutTime' in races_clean.columns:\n",
    "        races_clean = races_clean[races_clean['PitOutTime'].isna()]\n",
    "    if 'PitInTime' in races_clean.columns:\n",
    "        races_clean = races_clean[races_clean['PitInTime'].isna()]\n",
    "    \n",
    "    races_clean = races_clean[races_clean['LapTime_sec'].notna()]\n",
    "    races_clean = races_clean[races_clean['LapTime_sec'] > 0]\n",
    "    races_clean = races_clean[races_clean['LapTime_sec'] < 200]\n",
    "    \n",
    "    agg_dict = {\n",
    "        'LapTime_sec': 'median',\n",
    "        'SpeedI1': 'mean',\n",
    "        'SpeedI2': 'mean',\n",
    "        'SpeedFL': 'mean',\n",
    "        'SpeedST': 'mean',\n",
    "        'AirTemp': 'first',\n",
    "        'TrackTemp': 'first',\n",
    "        'Humidity': 'first',\n",
    "        'Pressure': 'first',\n",
    "        'Rainfall': 'max',\n",
    "        'WindSpeed': 'mean',\n",
    "        'FinalPosition': 'first',\n",
    "        'StartPosition': 'first',\n",
    "        'Team': 'first'\n",
    "    }\n",
    "    \n",
    "    agg_dict = {k: v for k, v in agg_dict.items() if k in races_clean.columns}\n",
    "    race_agg = races_clean.groupby(['Year', 'Event', 'Driver']).agg(agg_dict).reset_index()\n",
    "    \n",
    "    print(f\"âœ… Aggregated races: {len(race_agg)} records\")\n",
    "    \n",
    "    # Process qualifying\n",
    "    if not quali_df.empty:\n",
    "        quali_df['LapTime_sec'] = pd.to_timedelta(quali_df['LapTime'], errors='coerce').dt.total_seconds()\n",
    "        if 'Deleted' in quali_df.columns:\n",
    "            quali_df = quali_df[quali_df['Deleted'] == False]\n",
    "        quali_df = quali_df[quali_df['LapTime_sec'].notna()]\n",
    "        quali_df = quali_df[quali_df['LapTime_sec'] > 0]\n",
    "        \n",
    "        quali_agg = quali_df.groupby(['Year', 'Event', 'Driver']).agg({\n",
    "            'LapTime_sec': 'min',\n",
    "            'SpeedI1': 'mean',\n",
    "            'SpeedFL': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        quali_agg['QualiPosition'] = quali_agg.groupby(['Year', 'Event'])['LapTime_sec'].rank(method='min')\n",
    "        quali_agg.rename(columns={\n",
    "            'LapTime_sec': 'Quali_BestLapTime',\n",
    "            'SpeedI1': 'Quali_AvgSpeed',\n",
    "            'SpeedFL': 'Quali_MaxSpeed'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        race_agg = race_agg.merge(quali_agg, on=['Year', 'Event', 'Driver'], how='left')\n",
    "        print(f\"âœ… Merged qualifying data\")\n",
    "    \n",
    "    # Process practice\n",
    "    if not practice_df.empty:\n",
    "        practice_df['LapTime_sec'] = pd.to_timedelta(practice_df['LapTime'], errors='coerce').dt.total_seconds()\n",
    "        if 'Deleted' in practice_df.columns:\n",
    "            practice_df = practice_df[practice_df['Deleted'] == False]\n",
    "        practice_df = practice_df[practice_df['LapTime_sec'].notna()]\n",
    "        practice_df = practice_df[practice_df['LapTime_sec'] > 0]\n",
    "        practice_df = practice_df[practice_df['LapTime_sec'] < 200]\n",
    "        \n",
    "        practice_agg = practice_df.groupby(['Year', 'Event', 'Driver']).agg({\n",
    "            'LapTime_sec': 'median',\n",
    "            'SpeedI1': 'mean',\n",
    "            'SpeedST': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        practice_agg.rename(columns={\n",
    "            'LapTime_sec': 'Practice_MedianLapTime',\n",
    "            'SpeedI1': 'Practice_AvgSpeed',\n",
    "            'SpeedST': 'Practice_MaxSpeed'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        race_agg = race_agg.merge(practice_agg, on=['Year', 'Event', 'Driver'], how='left')\n",
    "        print(f\"âœ… Merged practice data\")\n",
    "    \n",
    "    # Process sprint\n",
    "    if not sprint_df.empty:\n",
    "        sprint_results = sprint_df.groupby(['Year', 'Event', 'Driver']).agg({\n",
    "            'FinalPosition': 'first'\n",
    "        }).reset_index()\n",
    "        sprint_results.rename(columns={'FinalPosition': 'SprintPosition'}, inplace=True)\n",
    "        \n",
    "        race_agg = race_agg.merge(sprint_results, on=['Year', 'Event', 'Driver'], how='left')\n",
    "        race_agg['StartPosition'] = race_agg['SprintPosition'].fillna(race_agg['StartPosition'])\n",
    "        print(f\"âœ… Merged sprint data\")\n",
    "    \n",
    "    # Use qualifying as start position if missing\n",
    "    race_agg['StartPosition'] = race_agg['StartPosition'].fillna(race_agg['QualiPosition'])\n",
    "    \n",
    "    # Engineer features\n",
    "    speed_cols = [c for c in ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST'] if c in race_agg.columns]\n",
    "    if speed_cols:\n",
    "        race_agg['Race_AvgSpeed'] = race_agg[speed_cols].mean(axis=1)\n",
    "    \n",
    "    if 'TrackTemp' in race_agg.columns and 'AirTemp' in race_agg.columns:\n",
    "        race_agg['TempDiff'] = race_agg['TrackTemp'] - race_agg['AirTemp']\n",
    "    \n",
    "    if 'Rainfall' in race_agg.columns:\n",
    "        race_agg['IsWet'] = (race_agg['Rainfall'] > 0).astype(int)\n",
    "    \n",
    "    if 'Practice_MedianLapTime' in race_agg.columns and 'Quali_BestLapTime' in race_agg.columns:\n",
    "        race_agg['PaceDelta'] = race_agg['Practice_MedianLapTime'] - race_agg['Quali_BestLapTime']\n",
    "    \n",
    "    # For 2025, use historical performance from all previous data (2021-2024)\n",
    "    # Load historical data\n",
    "    historical_data = []\n",
    "    for year in [2021, 2022, 2023, 2024]:\n",
    "        race_file = os.path.join(DATA_DIR, f'{year}_races.csv')\n",
    "        if os.path.exists(race_file):\n",
    "            hist = pd.read_csv(race_file)\n",
    "            historical_data.append(hist)\n",
    "    \n",
    "    if historical_data:\n",
    "        hist_df = pd.concat(historical_data, ignore_index=True)\n",
    "        hist_df = hist_df[hist_df['FinalPosition'].notna()]\n",
    "        \n",
    "        driver_avg = hist_df.groupby('Driver')['FinalPosition'].mean().to_dict()\n",
    "        team_avg = hist_df.groupby('Team')['FinalPosition'].mean().to_dict()\n",
    "        \n",
    "        race_agg['Driver_AvgPosition'] = race_agg['Driver'].map(driver_avg)\n",
    "        race_agg['Team_AvgPosition'] = race_agg['Team'].map(team_avg)\n",
    "        \n",
    "        print(f\"âœ… Added historical performance features\")\n",
    "    \n",
    "    # Encode categoricals using training encoders\n",
    "    encoders = model_data['encoders']\n",
    "    \n",
    "    for col in ['Driver', 'Team', 'Event']:\n",
    "        if col in race_agg.columns and col in encoders:\n",
    "            le = encoders[col]\n",
    "            race_agg[f'{col}_encoded'] = race_agg[col].apply(\n",
    "                lambda x: le.transform([str(x)])[0] if str(x) in le.classes_ else -1\n",
    "            )\n",
    "    \n",
    "    print(f\"âœ… Encoded categorical variables\")\n",
    "    \n",
    "    return race_agg\n",
    "\n",
    "# ==============================================================================\n",
    "# MAKE PREDICTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def predict_2025(data_2025, model_data):\n",
    "    \"\"\"Make predictions for 2025\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MAKING PREDICTIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model = model_data['model']\n",
    "    features = model_data['features']\n",
    "    \n",
    "    # Prepare features\n",
    "    X = data_2025[features].copy()\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Round to nearest integer and clip to valid range\n",
    "    predictions = np.clip(np.round(predictions), 1, 20)\n",
    "    \n",
    "    # Add predictions to dataframe\n",
    "    results = data_2025[['Year', 'Event', 'Driver', 'Team', 'StartPosition', 'FinalPosition']].copy()\n",
    "    results['PredictedPosition'] = predictions\n",
    "    results['Error'] = results['PredictedPosition'] - results['FinalPosition']\n",
    "    results['AbsError'] = np.abs(results['Error'])\n",
    "    \n",
    "    print(f\"âœ… Predicted {len(results)} driver-race combinations\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ==============================================================================\n",
    "# EVALUATE\n",
    "# ==============================================================================\n",
    "\n",
    "def evaluate_predictions(results):\n",
    "    \"\"\"Evaluate prediction accuracy\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EVALUATION METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall metrics\n",
    "    rmse = np.sqrt(mean_squared_error(results['FinalPosition'], results['PredictedPosition']))\n",
    "    mae = mean_absolute_error(results['FinalPosition'], results['PredictedPosition'])\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Overall Performance:\")\n",
    "    print(f\"   RMSE: {rmse:.2f} positions\")\n",
    "    print(f\"   MAE:  {mae:.2f} positions\")\n",
    "    \n",
    "    # Per-race performance\n",
    "    print(f\"\\nðŸ“Š Per-Race Performance:\")\n",
    "    race_metrics = results.groupby('Event').agg({\n",
    "        'AbsError': 'mean',\n",
    "        'Error': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    race_metrics.columns = ['MAE', 'Mean_Error', 'Std_Error']\n",
    "    race_metrics = race_metrics.sort_values('MAE')\n",
    "    \n",
    "    print(f\"\\nBest predictions (lowest error):\")\n",
    "    print(race_metrics.head(5).to_string())\n",
    "    \n",
    "    print(f\"\\nWorst predictions (highest error):\")\n",
    "    print(race_metrics.tail(5).to_string())\n",
    "    \n",
    "    # Per-driver performance\n",
    "    driver_metrics = results.groupby('Driver').agg({\n",
    "        'AbsError': 'mean',\n",
    "        'FinalPosition': 'count'\n",
    "    }).round(2)\n",
    "    driver_metrics.columns = ['MAE', 'Races']\n",
    "    driver_metrics = driver_metrics[driver_metrics['Races'] >= 3]  # At least 3 races\n",
    "    driver_metrics = driver_metrics.sort_values('MAE')\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Per-Driver Performance (drivers with 3+ races):\")\n",
    "    print(f\"\\nMost predictable drivers:\")\n",
    "    print(driver_metrics.head(5).to_string())\n",
    "    \n",
    "    print(f\"\\nLeast predictable drivers:\")\n",
    "    print(driver_metrics.tail(5).to_string())\n",
    "    \n",
    "    # Prediction accuracy by position\n",
    "    results['PositionBucket'] = pd.cut(results['FinalPosition'], \n",
    "                                        bins=[0, 3, 10, 20], \n",
    "                                        labels=['Podium', 'Midfield', 'Back'])\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Accuracy by Position:\")\n",
    "    position_metrics = results.groupby('PositionBucket')['AbsError'].agg(['mean', 'std']).round(2)\n",
    "    print(position_metrics.to_string())\n",
    "    \n",
    "    return rmse, mae, race_metrics, driver_metrics\n",
    "\n",
    "# ==============================================================================\n",
    "# SAVE RESULTS\n",
    "# ==============================================================================\n",
    "\n",
    "def save_results(results, rmse, mae, race_metrics, driver_metrics, model_data):\n",
    "    \"\"\"Save predictions and evaluation report\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SAVING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Save predictions\n",
    "    results_save = results[['Year', 'Event', 'Driver', 'Team', 'StartPosition', \n",
    "                             'FinalPosition', 'PredictedPosition', 'Error', 'AbsError']]\n",
    "    results_save = results_save.sort_values(['Event', 'FinalPosition'])\n",
    "    results_save.to_csv(OUTPUT_PREDICTIONS, index=False)\n",
    "    \n",
    "    print(f\"âœ… Predictions saved: {OUTPUT_PREDICTIONS}\")\n",
    "    \n",
    "    # Save evaluation report\n",
    "    with open(OUTPUT_EVALUATION, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"F1 2025 RACE PREDICTIONS - EVALUATION REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Model Training RMSE: {model_data['training_rmse']:.2f} positions\\n\")\n",
    "        f.write(f\"2025 Test RMSE: {rmse:.2f} positions\\n\")\n",
    "        f.write(f\"2025 Test MAE: {mae:.2f} positions\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"PER-RACE PERFORMANCE\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(race_metrics.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"PER-DRIVER PERFORMANCE (3+ races)\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(driver_metrics.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"SAMPLE PREDICTIONS\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        # Show first race in detail\n",
    "        first_race = results['Event'].iloc[0]\n",
    "        first_race_results = results[results['Event'] == first_race].sort_values('FinalPosition')\n",
    "        f.write(f\"Example: {first_race}\\n\\n\")\n",
    "        f.write(first_race_results[['Driver', 'StartPosition', 'PredictedPosition', 'FinalPosition', 'Error']].to_string(index=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"âœ… Evaluation report saved: {OUTPUT_EVALUATION}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"F1 2025 RACE PREDICTIONS & EVALUATION\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    model_data = load_trained_model()\n",
    "    if model_data is None:\n",
    "        return\n",
    "    \n",
    "    # Load 2025 data\n",
    "    races_2025, quali_2025, practice_2025, sprint_2025 = load_2025_data()\n",
    "    \n",
    "    if races_2025.empty:\n",
    "        print(\"\\nâŒ No 2025 race data found! Run 1_download_data.py first\")\n",
    "        return\n",
    "    \n",
    "    # Process 2025 data\n",
    "    data_2025 = process_2025_data(races_2025, quali_2025, practice_2025, sprint_2025, model_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    results = predict_2025(data_2025, model_data)\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse, mae, race_metrics, driver_metrics = evaluate_predictions(results)\n",
    "    \n",
    "    # Save\n",
    "    save_results(results, rmse, mae, race_metrics, driver_metrics, model_data)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ… PREDICTION & EVALUATION COMPLETE!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ðŸ“ Check outputs:\")\n",
    "    print(f\"   - {OUTPUT_PREDICTIONS}\")\n",
    "    print(f\"   - {OUTPUT_EVALUATION}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
